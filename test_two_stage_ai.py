#!/usr/bin/env python3
"""
Two-stage AI response system test
"""

import asyncio
import sys
import os

# Add the src directory to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from google import genai
from app.services import AIService
from app.services.database_helper import DatabaseHelper

async def test_two_stage_ai():
    """ë‘ ë‹¨ê³„ AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë‘ ë‹¨ê³„ AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # Mock objects for testing
    class MockMCPClient:
        def __init__(self):
            self.session = "mock_session"
    
    class MockGeminiClient:
        def __init__(self):
            self.aio = self
            self.models = self
        
        async def generate_content(self, model, contents, config):
            """Mock response for testing"""
            print(f"ğŸ“ Mock AI í˜¸ì¶œ: {model}")
            print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(contents)}ì")
            print(f"âš™ï¸ ì„¤ì •: tools={hasattr(config, 'tools')}, thinking={hasattr(config, 'thinking_config')}")
            
            # Mock response object
            class MockResponse:
                def __init__(self, text):
                    self.text = text
                    self.candidates = []
            
            if hasattr(config, 'tools') and hasattr(config, 'thinking_config'):
                # This should not happen in the two-stage system
                return MockResponse("ERROR: tools and thinking_config used together")
            elif hasattr(config, 'tools'):
                # Stage 1: Tool usage
                return MockResponse("1ë‹¨ê³„: MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„ì„ì›¹ ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            else:
                # Stage 2: Structured output
                mock_json = '''{"message": "2ë‹¨ê³„: êµ¬ì¡°í™”ëœ ì¶œë ¥ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì— ë‹µë³€í•©ë‹ˆë‹¤.", "script_updates": {"action": "create", "script": "console.log('test');"}}'''
                return MockResponse(mock_json)
    
    # Test setup
    mock_gemini = MockGeminiClient()
    mock_mcp = MockMCPClient()
    mock_db = DatabaseHelper("mock_db_path")
    
    # Create AI service
    ai_service = AIService(mock_gemini, mock_mcp, mock_db)
    
    # Mock user data
    ai_service.db_helper.get_user_sites = lambda user_id, owner_id: [
        {"site_code": "test", "access_token": "encrypted_token", "site_name": "Test Site"}
    ]
    ai_service.db_helper._decrypt_token = lambda token: "decrypted_token"
    ai_service.mcp_client.call_tool = lambda tool, params: None
    
    # Test chat history
    chat_history = [
        {"message_type": "user", "message": "í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”", "created_at": "2024-01-01"}
    ]
    
    try:
        print("\nğŸš€ ë‘ ë‹¨ê³„ AI ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸")
        response_text, metadata = await ai_service.generate_gemini_response(
            chat_history=chat_history,
            user_id="test_user",
            metadata='{"current_script": {}}'
        )
        
        print(f"âœ… ì‘ë‹µ ìƒì„± ì„±ê³µ!")
        print(f"ğŸ“„ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„°: {metadata}")
        
        if "1ë‹¨ê³„" in response_text and "2ë‹¨ê³„" in response_text:
            print("âŒ ì˜¤ë¥˜: ë‘ ë‹¨ê³„ê°€ ë™ì‹œì— ì‹¤í–‰ë¨")
        elif "2ë‹¨ê³„" in response_text:
            print("âœ… ì„±ê³µ: ë‘ ë‹¨ê³„ ë¶„ë¦¬ ì‘ë™ í™•ì¸")
        else:
            print("âš ï¸  ê²½ê³ : ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(test_two_stage_ai())